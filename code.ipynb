{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e0c3db",
   "metadata": {},
   "source": [
    "# üß† YOLOv11 Object Detection Notebook\n",
    "\n",
    "Welcome to this YOLOv11-based object detection project!  \n",
    "This notebook demonstrates how to use the **Ultralytics YOLOv11** model for training, real-time webcam inference, and video file processing.\n",
    "\n",
    "YOLO (You Only Look Once) is a state-of-the-art, real-time object detection system known for its speed and accuracy. In this notebook, we utilize the `yolo11n.pt` (nano version) model for efficient detection tasks, especially suited for resource-constrained environments like CPU-based systems.\n",
    "\n",
    "### üîç What You'll Learn\n",
    "- How to train YOLOv11 on a custom or sample dataset.\n",
    "- How to run object detection on images.\n",
    "- How to integrate YOLO with a webcam for real-time inference.\n",
    "- How to apply YOLOv11 to detect objects in video files.\n",
    "- How to export the trained model in ONNX format for deployment.\n",
    "\n",
    "This notebook is ideal for anyone looking to explore computer vision using modern deep learning techniques in Python.\n",
    "\n",
    "Let's dive into building smarter vision systems with YOLOv11! üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f78c04",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Training the YOLOv11 Model\n",
    "\n",
    "In this section, we initialize the YOLOv11 nano model (`yolo11n.pt`) and train it using the sample `coco8.yaml` dataset. The model is trained for 100 epochs on images of size 640x640 using the CPU. After training, we evaluate the model performance on the validation set and export the trained model in ONNX format for broader compatibility and deployment.\n",
    "\n",
    "Steps performed:\n",
    "- Load the YOLOv11 nano model.\n",
    "- Train the model using `coco8.yaml` dataset.\n",
    "- Evaluate the model performance using `.val()`.\n",
    "- Perform inference on a sample image (`image.jpg`).\n",
    "- Export the model to ONNX format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "train_results = model.train(\n",
    "    data = \"coco8.yaml\",\n",
    "    epochs = 100,\n",
    "    imgsz = 640,\n",
    "    device = \"cpu\",\n",
    ")\n",
    "\n",
    "metrics = model.val()\n",
    "\n",
    "results = model(\"path_to_your_image.jpg\")\n",
    "\n",
    "results[0].show()\n",
    "\n",
    "path = model.export(format = \"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee31d85",
   "metadata": {},
   "source": [
    "## üì∑ Real-Time Object Detection using Webcam\n",
    "\n",
    "This section demonstrates how to perform real-time object detection using the YOLOv11 nano model (`yolo11n.pt`) on webcam feed. The model processes each frame captured from the webcam, detects objects, and displays the annotated output in a window.\n",
    "\n",
    "Steps performed:\n",
    "- Load the pre-trained YOLOv11 model.\n",
    "- Access the default webcam using OpenCV.\n",
    "- Perform real-time object detection on each captured frame.\n",
    "- Annotate frames with bounding boxes and class labels.\n",
    "- Display the processed frames in a window.\n",
    "- Press `q` to exit the inference loop and close the webcam stream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 for default webcam, or replace with a path to an external webcam\n",
    "\n",
    "# Check if the webcam opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    # Run inference on the frame from the webcam\n",
    "    results = model(frame)\n",
    "\n",
    "    # Render results on the frame\n",
    "    frame_with_boxes = results[0].plot()  # Annotate the frame with bounding boxes\n",
    "\n",
    "    # Display the frame with detections\n",
    "    cv2.imshow(\"Webcam YOLO Inference\", frame_with_boxes)\n",
    "\n",
    "    # Exit the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358b5d6",
   "metadata": {},
   "source": [
    "## üé• Object Detection on Video File\n",
    "\n",
    "In this section, the YOLOv11 nano model (`yolo11n.pt`) is used to perform object detection on a pre-recorded video. Each frame of the video is processed for object detection, annotated with bounding boxes and class labels, and saved to a new output video file.\n",
    "\n",
    "Steps performed:\n",
    "- Load the pre-trained YOLOv11 model.\n",
    "- Open and read the input video file using OpenCV.\n",
    "- For each frame:\n",
    "  - Run inference using YOLOv11.\n",
    "  - Annotate detections on the frame.\n",
    "  - Write the annotated frame to an output video file.\n",
    "  - Optionally display the detection in real-time.\n",
    "- Save the final processed video as `output_video.mp4`.\n",
    "- Press `q` to stop early during display, or wait until the video finishes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained YOLOv11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Path to the input video\n",
    "video_path = \"./videos/5.mp4\"  # Replace with your actual video file\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' or 'mp4v'\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Process video frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv11 inference\n",
    "    results = model(frame)\n",
    "\n",
    "    # Annotate the frame with detections\n",
    "    frame_with_boxes = results[0].plot()\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame_with_boxes)\n",
    "\n",
    "    # (Optional) Display the video while processing\n",
    "    resized_frame = cv2.resize(frame_with_boxes, (800, 600))  # Width x Height\n",
    "    cv2.imshow(\"YOLO Video Inference\", resized_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04146c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  **Thank You!**\n",
    "\n",
    "Thank you for exploring this YOLOv11 Object Detection project!  \n",
    "I hope this notebook helped you understand how to train, test, and deploy object detection models using Ultralytics YOLO.\n",
    "\n",
    "Whether you're a beginner stepping into the world of computer vision or a developer refining real-time detection pipelines, I appreciate your time and curiosity.\n",
    "\n",
    "Happy Coding and keep building amazing things! üöÄ\n",
    "\n",
    "‚Äî *Muhammad Hassan Saboor*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
